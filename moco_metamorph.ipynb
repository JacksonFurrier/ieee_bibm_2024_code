{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import unittest\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import astra\n",
    "\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.util import random_noise\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "from pykeops.torch import Vi, Vj\n",
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "from src.algs.arm import lv_indicator\n",
    "from src.tools.recon.projector import forward_projector\n",
    "from src.tools.lddmm.manifold_mapping import pull_back\n",
    "from src.tools.manip.manip import normalize_volume\n",
    "\n",
    "# data fetching and handling\n",
    "from data.check_database import load_remote_data\n",
    "from data.fetch_data import fetch_data\n",
    "from src.tools.data.loadvolumes import LoadVolumes\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as torch_transform\n",
    "from torch.autograd import grad\n",
    "import torch\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "from math import prod\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torchdeviceId = torch.device(\"cuda:0\") if use_cuda else \"cpu\"\n",
    "\n",
    "from kornia.filters import SpatialGradient as k_grad\n",
    "from kornia.filters import GaussianBlur2d\n",
    "\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "from src.util.timer import tic, toc\n",
    "import time\n",
    "\n",
    "err_eps = 1e-10"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup for the data storage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe6f3b846c58bb01"
  },
  {
   "cell_type": "code",
   "source": [
    "lv_model_volume = None\n",
    "lv_model_frames = None\n",
    "lv_motion_frames = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83b526c635119120",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "volume = np.zeros([64, 64, 64])\n",
    "params = dict(a=1, c=2, sigma=-1)\n",
    "transform_params = [np.eye(3, 3), [16, 16, 0], 1.5]\n",
    "\n",
    "recon_mode = 'basic'\n",
    "fprojector = forward_projector(recon_mode)\n",
    "\n",
    "# getting the model left ventricle volume and its' forward projected frames\n",
    "lv_model_volume = lv_indicator(volume, params, transform_params)\n",
    "lv_model_frames = fprojector(lv_model_volume)\n",
    "lv_motion_frames = np.zeros(lv_model_frames.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "846f2ad3af246126",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hamiltonian ODEs solvers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a863577e8a0dfe"
  },
  {
   "cell_type": "code",
   "source": [
    "def RalstonIntegrator(): # correct but it should be optimized!\n",
    "    def f(ODESystem, x0, nt, deltat=1.0):\n",
    "        x = tuple(map(lambda x: x.clone(), x0)) # we need just the last element on which we do pull-back on\n",
    "        dt = deltat / nt\n",
    "        # l = [tuple([x[0], x[1][-1]])]\n",
    "        l = [x[1][0]]\n",
    "        for i in range(nt):\n",
    "            xdot = ODESystem(*x)\n",
    "            xi = tuple(map(lambda x, xdot: x + (2 * dt / 3) * xdot, x, xdot))\n",
    "            xdoti = ODESystem(*xi)\n",
    "            x = tuple(\n",
    "                map(\n",
    "                    lambda x, xdot, xdoti: x + (0.25 * dt) * (xdot + 3 * xdoti),\n",
    "                    x,\n",
    "                    xdot,\n",
    "                    xdoti,\n",
    "                )\n",
    "            )\n",
    "            # l.append(tuple([x[0], x[1][-1]]))\n",
    "            l.append(x[1][i])\n",
    "        return l\n",
    "\n",
    "    return f"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a2a4a8fb704e1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def Shooting(z0, im0, K, K_Q, lam, rho, nt=63, Integrator=RalstonIntegrator()):\n",
    "    return Integrator(HamiltonianSystem(K, K_Q, z0, lam, rho), (z0, im0), nt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82c1e2279d12b35d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# to convert torch.tensor lists -> tensor\n",
    "def Gradient(fun):\n",
    "    return torch.stack(torch.gradient(fun), dim=0) # (C, W, H) format\n",
    "    # return k_grad()(fun[..., None, None])[..., 0, 0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc53e2538daf4b4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def Residual(K_Q):\n",
    "    def R(z0):\n",
    "        return (z0 ** 2).sum()\n",
    "    return R"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b5e2e6d4e45bb17",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# fix this according to [2]\n",
    "def DiffNorm(K):\n",
    "    def V(z0, im):\n",
    "        q = z0.double() * Gradient(im)\n",
    "        return (q * K(q[None, ...])[0]).sum()\n",
    "\n",
    "    return V"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a76e326d319ddba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# try alternative norms too  \n",
    "def Hamiltonian(K, K_Q): # update Hamiltonian to the shooting scheme as in [1], [2]\n",
    "    def H(im):\n",
    "        # print(im.sum().item(), im.min().item(), im.max().item())\n",
    "        return (K_Q(im)).sum()\n",
    "\n",
    "    return H"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a261760d7cd08857",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def MetaMorphosisLoss(K, K_Q, lam=0, rho=1):\n",
    "    def loss(z0, im0):\n",
    "        # p, imt = Shooting(z0, im0, K, K_Q, lam, rho)\n",
    "        imt = torch.stack(Shooting(z0, im0, K, K_Q, lam, rho), dim=0)\n",
    "\n",
    "        return Hamiltonian(K, K_Q)(imt) + lam * (DiffNorm(K)(z0, imt[-1]) + rho * Residual(K_Q)(z0))\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7311d1d4ba8446d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def HamiltonianSystem(K, K_Q, z0, lam, rho):\n",
    "    H = Hamiltonian(K, K_Q)\n",
    "    R = Residual(K_Q)\n",
    "    D = DiffNorm(K)\n",
    "\n",
    "    def HS(z0, im0):\n",
    "        Gz0, Gim0 = grad(H(im0) + lam * (D(z0[-1], im0[-1]) + rho * R(z0[-1])), (z0, im0), allow_unused=True)\n",
    "        return -Gim0, Gz0\n",
    "\n",
    "    return HS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae802eb0d8f7f5c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def Flow(z0, im0, K, K_Q, lam, rho, nt=63, Integrator=RalstonIntegrator()):\n",
    "    return Integrator(HamiltonianSystem(K, K_Q, z0, lam, rho), (z0, im0), nt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abb6c5d7b10eb635",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def Optimize(loss, z0, im0, lr=0.5, max_it=1):\n",
    "    optimizer = torch.optim.LBFGS([z0], max_eval=1, max_iter=1, lr=lr, history_size=1)\n",
    "    # optimizer = torch.optim.Adadelta([z0], lr=lr, rho=0.9, weight_decay=0)\n",
    "    history = []\n",
    "    print(\"performing optimization...\")\n",
    "    start = time.time()\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        L = loss(z0, im0)\n",
    "        l = L.detach().cpu().numpy()\n",
    "        print(\"Loss: \", l)\n",
    "        history.append(l)\n",
    "        L.backward()\n",
    "        return L\n",
    "\n",
    "    for i in range(max_it):\n",
    "        print(\"it \", i, \": \", end=\"\")\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    print(\"Optimization (L-BFGS) time: \", round(time.time() - start, 2), \" seconds\")\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca9edb1e607ed48c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def PlotDeformations(list_deformations):\n",
    "    fig, axs = plt.subplots(8, 8)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            ind = i * 8 + j\n",
    "            axs[i, j].imshow(list_deformations[ind].cpu().detach().numpy())\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b96ffa1dc2166e43",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main metamorphosis implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d11006587d168e16"
  },
  {
   "cell_type": "code",
   "source": [
    "def metamorphosis(a_frames, a_lddmm_params, a_eps=0.5):\n",
    "    # getting first and last frame\n",
    "    first_frame = a_frames[0]\n",
    "    last_frame = a_frames[-1]\n",
    "    \n",
    "    # for \"time-series\" growth model\n",
    "    frames = torch.from_numpy(a_frames).float().cuda()\n",
    "    frames.requires_grad = True\n",
    "    \n",
    "    # getting lddmm params\n",
    "    T, lddmm_iteration, sigma, alpha, beta, epsilon = a_lddmm_params.values()\n",
    "\n",
    "    # error bound for iterations\n",
    "    eps = a_eps\n",
    "\n",
    "    height, width = first_frame.shape\n",
    "\n",
    "    time_res = 64\n",
    "\n",
    "    torchdtype = torch.float32\n",
    "\n",
    "    # initial values for GS\n",
    "    im0 = torch.from_numpy(first_frame).cuda().requires_grad_(True)\n",
    "    im1 = torch.from_numpy(last_frame).cuda().requires_grad_(True)\n",
    "\n",
    "    # z0 = torch.from_numpy(first_frame - last_frame).requires_grad_(True)\n",
    "    z0 = torch.rand([width, height], dtype=torchdtype).cuda().requires_grad_(True)\n",
    "    rand_init = torch.rand([time_res, width, height], dtype=torchdtype).cuda().requires_grad_(True)\n",
    "    # z0 = torch.zeros([width, height], dtype=torchdtype).requires_grad_(True)\n",
    "    # z0 = torch.ones([width, height], dtype=torchdtype).requires_grad_(True)\n",
    " \n",
    "    # lagrange multiplier and intensity change hyperparameters\n",
    "    lam = 1e0\n",
    "    rho = 1e0\n",
    "\n",
    "    tic()    \n",
    "    S = SamplesLoss(loss='sinkhorn', p=2, blur=eps, potentials=True, reach=1.0, scaling=0.95, diameter=10.0, debias=False)\n",
    "        \n",
    "    # K_Q = lambda q: ((im1 - q)**2)\n",
    "    # for two images\n",
    "    # K_Q = lambda q: S(q.flatten()[None, :], im1.flatten()[None, :])[0] - S(q.flatten()[None, :], q.flatten()[None, :])[0]\n",
    "    K_Q = lambda q: S(torch.flatten(q, start_dim=1), torch.flatten(frames, start_dim=1))[0] - S(torch.flatten(q, start_dim=1), torch.flatten(q, start_dim=1))[0]\n",
    "    # K_Q = lambda q: torch.nn.functional.kl_div(im1, q, reduction='none')\n",
    "    K = GaussianBlur2d(kernel_size=1, sigma=(sigma, sigma))\n",
    "    \n",
    "    loss = MetaMorphosisLoss(K, K_Q, lam=lam, rho=rho)\n",
    "\n",
    "    # gradient for GS\n",
    "    learning_rate = 0.16\n",
    "\n",
    "    # Geodesic shooting\n",
    "    history = Optimize(loss, z0, rand_init, learning_rate, lddmm_iteration)\n",
    "    \n",
    "    # Computing and plotting deformations\n",
    "    list_def = Flow(z0, frames, K, K_Q, lam=lam, rho=rho, nt=63)\n",
    "    \n",
    "    PlotDeformations(list_def)\n",
    "    plt.show()\n",
    "    \n",
    "    toc()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c20a239d84bb913a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parallel hole tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2db09085b2ace91d"
  },
  {
   "cell_type": "code",
   "source": [
    "dicom_loader = LoadVolumes()\n",
    "\n",
    "# initialize data fetching from remote, configuration is in data/remote.yml\n",
    "data_loaded = False\n",
    "url, datasets = load_remote_data()\n",
    "\n",
    "# fetch specific patient data\n",
    "dicom_name = datasets['raw/']['turkey_par/'][10]\n",
    "data_url = url + '/raw/' + 'turkey_par/' + dicom_name\n",
    "\n",
    "# fetch the data from remote\n",
    "data = fetch_data(data_url)\n",
    "\n",
    "# load data with the dicom loader\n",
    "frames, data_loaded = dicom_loader.LoadSinglePatient(data)\n",
    "\n",
    "# normalizing the frame values\n",
    "normalize_volume(frames)\n",
    "frames = frames + 1  # just to get rid of NaNs in log computation\n",
    "assert (data_loaded)\n",
    "\n",
    "num_frames, width, height = frames.shape\n",
    "\n",
    "lddmm_params = dict(T=num_frames * 32, K=10, sigma=5, alpha=1000, gamma=1, epsilon=1e-6)\n",
    "\n",
    "indices = [0, -1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdba5a31bda4f4d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# metamorphosis(frames[indices], lddmm_params, a_eps=1e-4)\n",
    "metamorphosis(frames, lddmm_params, a_eps=1e-4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d88bf808aa702d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "plt.imshow(frames[indices[1], :, :], aspect='equal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff03bec5c91150ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments with loss function, divergences, distances and Brenier maps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72c92069f6f9582"
  },
  {
   "cell_type": "code",
   "source": [
    "eps = 1e-4\n",
    "\n",
    "first_frame = frames[0]\n",
    "last_frame = frames[-1]\n",
    "\n",
    "torchdtype = torch.float32\n",
    "\n",
    "im0 = torch.rand([64, 64], dtype=torchdtype).cuda()\n",
    "im0.requires_grad = True\n",
    "im1 = torch.from_numpy(last_frame).float().cuda()\n",
    "im1.requires_grad = True\n",
    "mass = 0.75 * torch.ones([1]).cuda()\n",
    "\n",
    "S = SamplesLoss(loss='sinkhorn', p=2, blur=eps, potentials=True, reach=1.0, scaling=0.95, diameter=10.0, debias=False)\n",
    "\n",
    "niter = 40\n",
    "lr = 0.16\n",
    "\n",
    "for i in range(niter):\n",
    "    im0.requires_grad = True\n",
    "    F_bias, _ = S(im0.flatten()[None, :], im0.flatten()[None, :])\n",
    "    F, _ = S(im0.flatten()[None, :], im1.flatten()[None, :])\n",
    "    \n",
    "    g_x_bias = grad(F_bias.sum(), [im0], allow_unused=True)[0]\n",
    "    g_x = grad(F.sum(), [im0], allow_unused=True)[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        im0 = im0 - lr * (g_x - g_x_bias)\n",
    "    im0.requires_grad = False\n",
    "    print(((im1 - im0)**2).sum().item())\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "plt.imshow((im0).cpu().detach().numpy(), aspect='equal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0f7844d7c3f1c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MPH tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25da39874f9d94f5"
  },
  {
   "cell_type": "code",
   "source": [
    "dicom_loader = LoadVolumes()\n",
    "\n",
    "# initialize data fetching from remote, configuration is in data/remote.yml\n",
    "data_loaded = False\n",
    "url, datasets = load_remote_data()\n",
    "\n",
    "# implementing pinhole bordermap loading here\n",
    "\n",
    "# assemble here which data are we planning to download\n",
    "raw_file_name = datasets['utility/']['apt_72_bordermap/'][2]\n",
    "data_url = url + '/utility/' + 'apt_72_bordermap/' + raw_file_name\n",
    "\n",
    "# fetch the data from remote\n",
    "pinhole_bordermap_dat = fetch_data(data_url)\n",
    "pinhole_bordermap = np.reshape(np.frombuffer(pinhole_bordermap_dat.getvalue(), dtype=np.float32),\n",
    "                               [1024, 1024])  # antipattern to use exact burnt in numbers but I am lazy\n",
    "pinhole_bordermap = pinhole_bordermap[::4, ::4]\n",
    "\n",
    "dicom_file_name = datasets['simulated/']['motion_correction/'][0]['motion/'][\n",
    "    0]  # massive data, Nystrom compression needed\n",
    "data_url = url + '/simulated/' + 'motion_correction/motion/' + dicom_file_name\n",
    "\n",
    "# fetch the data from remote\n",
    "data = fetch_data(data_url)\n",
    "\n",
    "# load data with the dicom loader\n",
    "frames, data_loaded = dicom_loader.LoadSinglePatient(data)\n",
    "frames[:] = frames[:] * np.where(pinhole_bordermap > 0, 1, 0)\n",
    "\n",
    "# getting pixels that matter\n",
    "sqrt_masked_pixels = np.ceil(np.sqrt(np.sum(np.where(pinhole_bordermap > 0, 1, 0)))).astype(int)\n",
    "frames_compressed = np.zeros([frames.shape[0], sqrt_masked_pixels, sqrt_masked_pixels])\n",
    "non_zero_ind = np.nonzero(pinhole_bordermap)\n",
    "\n",
    "for i in range(frames.shape[0]):\n",
    "    cur_frame = np.resize(frames[i, non_zero_ind[0], non_zero_ind[1]], sqrt_masked_pixels * sqrt_masked_pixels)\n",
    "    frames_compressed[i] = np.reshape(cur_frame, [sqrt_masked_pixels, sqrt_masked_pixels])\n",
    "\n",
    "first_frame = frames_compressed[0]\n",
    "\n",
    "# normalizing the frame values\n",
    "normalize_volume(frames)\n",
    "frames = frames + 1  # just to get rid of NaNs in log computation\n",
    "\n",
    "assert (data_loaded)\n",
    "\n",
    "params = dict(T=16, K=100, sigma=64, alpha=1000, gamma=1,\n",
    "              epsilon=1)  # might not be the most optimal parameters so far\n",
    "\n",
    "num_frames, width, height = frames.shape\n",
    "\n",
    "lddmm_params = dict(T=num_frames * params.get('T'), K=30, sigma=1, alpha=1000, gamma=1, epsilon=1e-6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66fb12eca515cdf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "metamorphosis(frames[32:35], lddmm_params, a_eps=0.5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17131285273f33d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.close(\"all\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c266fec933c953b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e30f504c5606d079",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
